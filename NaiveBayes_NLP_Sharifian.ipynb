{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPfW0pvcbGMowKOG6yiuFpL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-Ali-S/NLP/blob/main/NaiveBayes_NLP_Sharifian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "(train_data,test_data)=tfds.load('imdb_reviews',split=['train','test[:40%]'],as_supervised=True)\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def tokenize_the_text(text):\n",
        "  text2lower=text.lower()\n",
        "  tokens= tokenizer.tokenize(text2lower)\n",
        "  tokens= [token for token in tokens if token not in stop_words]\n",
        "\n",
        "  return tokens\n",
        "\n",
        "\n",
        "positive_samples=[\n",
        "    (tokenize_the_text(text.numpy().decode('utf-8')) ,label.numpy())\n",
        "     for text ,label in train_data\n",
        "        if label.numpy()==1\n",
        "    ]\n",
        "\n",
        "negative_samples=[\n",
        "    (tokenize_the_text(text.numpy().decode('utf-8')),label.numpy())\n",
        "     for text ,label in train_data\n",
        "        if label.numpy()==0\n",
        "    ]\n",
        "\n",
        "\n",
        "positive_words = Counter()\n",
        "for tokens, _ in positive_samples[:100]:\n",
        "    positive_words.update(tokens)\n",
        "\n",
        "\n",
        "negative_words = Counter()\n",
        "for tokens, _ in negative_samples[:100]:\n",
        "    negative_words.update(tokens)\n",
        "\n",
        "\n",
        "positive_words_probability=Counter()\n",
        "negative_words_probability=Counter()\n",
        "\n",
        "\n",
        "total_positive_count = sum(positive_words.values())\n",
        "total_negative_count = sum(negative_words.values())\n",
        "\n",
        "for token in positive_words:\n",
        "  positive_words_probability[token]=positive_words[token]/total_positive_count\n",
        "\n",
        "for token in negative_words:\n",
        "  negative_words_probability[token]=negative_words[token]/total_negative_count\n",
        "\n",
        "\n",
        "\n",
        "def calcuate_proability_of_sentence(text):\n",
        "  total_prob_of_sentence=0.5 # length of a sample divided by the sum of the both(100/100+100)\n",
        "  negative_prob=1 * total_prob_of_sentence\n",
        "  positive_prob=1 * total_prob_of_sentence\n",
        "\n",
        "  for token in tokenize_the_text(text):\n",
        "    if positive_words_probability[token]==0 or positive_words_probability[token] is None or negative_words_probability[token]==0 or negative_words_probability[token] is None :\n",
        "      negative_prob *= 1\n",
        "      positive_prob *= 1\n",
        "    else:\n",
        "      negative_prob*= negative_words_probability[token]\n",
        "      positive_prob*= positive_words_probability[token]\n",
        "\n",
        "\n",
        "  return positive_prob, negative_prob\n",
        "\n",
        "\n",
        "\n",
        "test_data = test_data.take(20)\n",
        "\n",
        "true_positives = 0\n",
        "true_negatives = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "\n",
        "for text, label in test_data:\n",
        "    positive_prob, negative_prob = calcuate_proability_of_sentence(text.numpy().decode('utf-8'))\n",
        "\n",
        "\n",
        "    predicted_label = 1 if positive_prob > negative_prob else 0\n",
        "\n",
        "\n",
        "    if predicted_label == 1 and label.numpy() == 1:\n",
        "        true_positives += 1\n",
        "    elif predicted_label == 0 and label.numpy() == 0:\n",
        "        true_negatives += 1\n",
        "    elif predicted_label == 1 and label.numpy() == 0:\n",
        "        false_positives += 1\n",
        "    elif predicted_label == 0 and label.numpy() == 1:\n",
        "        false_negatives += 1\n",
        "\n",
        "    print(label)\n",
        "\n",
        "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) != 0 else 0\n",
        "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) != 0 else 0\n",
        "f_measure = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-measure:\", f_measure)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYQMKeaOg0Dw",
        "outputId": "3ec6302c-03af-460f-c0bf-3b89f0da9744"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}